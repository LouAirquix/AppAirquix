Welcome to the Airquix App! :)

The App captures real-time data from your surroundings to predict your current status using machine learning.

FEATURES:
- Camera & ML Classification:
  • Uses two ML models—Places365 (PyTorch) for scene recognition and a TFLite model for specific environment/vehicle cues.
- Activity Recognition:
  • Detects activities like walking, running, or driving via Google Play Services.
- Audio Classification:
  • Classifies ambient sounds in real-time with YAMNet to capture noise levels and characteristic sounds.
- GPS & Speed Monitoring:
  • Measures current speed to support status prediction.
- CSV Logging:
  • Aggregates image, audio, location, and activity data into CSV feature vectors for status prediction.

WHY?
By combining visual, audio, and motion data, Airquix01 builds a rich feature vector to accurately predict user status and context.

For more info, visit our GitHub Repository:
https://github.com/LouAirquix/AppAirquix

SUPPORT:
For questions or problems, contact: lperalt_bonell@hotmail.de
